---
title: "Models for unbounded count data"
institute: "Department of Mathematical Sciences, NTNU"
author: "Bert van der Veen"
output: 
  beamer_presentation:
    toc: false
    slide_level: 2
    latex_engine: lualatex
    includes:
      in_header: ../header.tex
header-includes:
  - \AtBeginSection{}
  - \useoutertheme{miniframes}
  - \setbeamertemplate{frametitle}{\vskip0.3cm\usebeamerfont*{frametitle}\insertframetitle\vskip-1.5ex\begin{beamercolorbox}[colsep=0.2pt, wd=\textwidth]{lower separation line head}\end{beamercolorbox}}
  - \setbeamercolor{lower separation line head}{bg=orange}
  - \definecolor{shadecolor}{RGB}{200, 200, 200}
  - \hypersetup{colorlinks,citecolor=orange,filecolor=red,linkcolor=brown,urlcolor=blue}
  - \definecolor{green}{RGB}{48, 69, 41}
  - \definecolor{darkorange}{RGB}{255, 150, 0}
  - \definecolor{gray}{RGB}{100, 100, 100}
  - \setbeamercolor{itemize item}{fg=orange}
  - \setbeamercolor{itemize subitem}{fg=orange}
  - \setbeamercolor{enumerate item}{fg=orange}
  - \setbeamercolor{enumerate subitem}{fg=orange}
  - \tcbuselibrary{skins}
  - \usepackage{emoji}
  - \usepackage{longtable,booktabs}
editor_options: 
  chunk_output_type: console
urlcolor: orange
---

```{r setup, include=FALSE}
library(knitr)

default_source_hook <- knit_hooks$get('source')
default_output_hook <- knit_hooks$get('output')

knit_hooks$set(
  source = function(x, options) {
    paste0(
      "\n::: {.codebox data-latex=\"\"}\n\n",
      default_source_hook(x, options),
      "\n\n:::\n\n")
  }
)

knit_hooks$set(
  output = function(x, options) {
    paste0(
      "\n::: {.codebox data-latex=\"\"}\n\n",
      default_output_hook(x, options),
      "\n\n:::\n\n")
  }
)

knitr::opts_chunk$set(echo = TRUE)
```


## Outline

- Models for count data
- Residual diagnostics in GLMs
- Other useful models

## Questions about yesterday?

\center

![](questions.jpg){width=40%}

# Recap

## The binomial GLM

\textbf{Response data}: $r$ the number of successes in $N$ trials\newline
\textbf{Predictor variables}: $x_i$ albeit continuous and/or categorical \newline
\textbf{Parameters}: probability of success $p_i$ in trial $i$\newline
\textbf{Goal}: estimate $pi_i$ for each observation

## Binomial GLM use

- When a linear regression is not appropriate :)
- For binary data or counts of successes/failures 

### Common examples

- OME signal identification
- cancer rates
- Predicting species' distributions
- Number of germinated plant seeds
- Prevalence of disease in a population
- Probability of observing a behavior
- Proportion of orchids \emoji{upside-down-face}

## Binomial link functions (2)

```{r, echo = FALSE}
x<-seq(binomial(link=logit)$linkinv(-5),binomial(link=logit)$linkinv(5),length.out=1000)
plot(binomial(link=logit)$linkfun(x),x, xlab = expression(pi[i]), ylab = expression(eta[i]), type="l")
x<-seq(binomial(link=probit)$linkinv(-5),binomial(link=probit)$linkinv(5),length.out=1000)
lines(binomial(link=probit)$linkfun(x),x, lty="dashed")
x<-seq(binomial(link=cloglog)$linkinv(-5),binomial(link=cloglog)$linkinv(5),length.out=1000)
lines(binomial(link=cloglog)$linkfun(x),x, lty="dotted")
x<-seq(from=exp(-exp(5)),to=exp(-exp(-5)),length.out=1000)
lines(-log(-log(x)),x, lty=4)
abline(v= 0, lty="dashed")
legend("bottomright", lty=c(1,2,3,4), legend = c("Logit","Probit", "Complementary log-log", "Log-log"))
```

# Poisson

## Typical count cases

- Number of caught fish
- Number of deaths due to lung cancer or other diseases
- Seizure counts
- Times a behavior is expressed
- Number of pidgeons in a city
- Number of [Bigfoot reports](https://zslpublications.onlinelibrary.wiley.com/doi/abs/10.1111/jzo.13148)
- Number of wrongful convictions
- Number of stars in the night sky

## The Poisson GLM

\textbf{Response data}: $k_i$ the count\newline
\textbf{Predictor variables}: $x_i$ albeit continuous and/or categorical \newline
\textbf{Parameters}: mean $\lambda$ \newline
\textbf{Goal}: estimate $\lambda_i$ for each observation

## The Poisson distribution

\columnsbegin
\column{0.5\textwidth}

\begin{equation}
\mathcal{L}(y_i;\Theta) = \text{exp}\{y_i\log(\lambda_i) - \lambda_i - \log(y_i!)\}
\end{equation}

\column{0.5\textwidth}


\hfill ![SimÃ©on Denis Poisson](Poisson.jpg){width=80%}

\columnsend

\textbf{The Poisson paramater $\lambda$ is the mean of the counting process}

## Is Poisson regression in the EF?

\begin{equation}
\mathcal{L}(y_i;\Theta) = \text{exp}\biggl\{\frac{y_i\textcolor{blue}{\log(\lambda)}+\textcolor{red}{\log(\lambda)}}{1} + \textcolor{orange}{\log(y_i!)}\biggr\}
\end{equation}

All GLMs can be formulated as:

\begin{equation}
\mathcal{L}(y_i;\Theta) = \text{exp}\{\frac{y_i\textcolor{blue}{\eta_i}-\textcolor{red}{b(\eta_i)}}{\textcolor{pink}{a(\phi)}} +\textcolor{orange}{c(y_i,\phi)}\}
\end{equation}

## The Poisson distribution visually

```{r, echo = FALSE, fig.height=5, fig.align="center"}
par(mfrow=c(2,2))
plot(table(y<-rpois(1000,1)), xlab = expression(y[i]), main = expression(lambda == 1), cex.main = 2, cex.lab = 1.5, ylab = "Frequency")
plot(table(y<-rpois(1000,5)), xlab = expression(y[i]), main = expression(lambda == 5), cex.main = 2, cex.lab = 1.5, ylab = "Frequency")
plot(table(y<-rpois(1000,10)), xlab = expression(y[i]), main = expression(lambda == 10), cex.main = 2, cex.lab = 1.5, ylab = "Frequency")
plot(table(y<-rpois(1000,100)), xlab = expression(y[i]), main = expression(lambda == 100), cex.main = 2, cex.lab = 1.5, ylab = "Frequency")
```

## Log-link function

So log is the canonical link. This looks like:

```{r, echo=FALSE, fig.height = 6}
x <- seq(-5,5,length.out=1000)
plot(x, exp(x), type = "l", xlab = expression(eta[i]), ylab = expression(lambda[i]))
segments(x0=0,x1=0, y0=-10, y1 = 1, col = "red")
segments(x0=0,x1=-10, y0=1, y1 = 1, col = "red")
segments(x0=2,x1=2, y0=-10, y1 =exp(2) , col = "red")
segments(x0=2,x1=-10, y0=exp(2), y1 =exp(2) , col = "red")
segments(x0=4,x1=4, y0=-10, y1 =exp(4) , col = "red")
segments(x0=4,x1=-10, y0=exp(4), y1 =exp(4) , col = "red")

```

## square root-link function

An alternative is the square root-link function $\lambda_i = (\alpha + x_i\beta)^2$

```{r, echo=FALSE, fig.height = 6}
x <- seq(-5,5,length.out=1000)
plot(x, (x)^2, type = "l", xlab = expression(eta[i]), ylab = expression(lambda[i]))
segments(x0=0,x1=0, y0=-10, y1 = 0, col = "red")
segments(x0=0,x1=-10, y0=0, y1 = 0, col = "red")
segments(x0=2,x1=2, y0=-10, y1 =4 , col = "red")
segments(x0=2,x1=-10, y0=4, y1 =4 , col = "red")
segments(x0=4,x1=4, y0=-10, y1 =16 , col = "red")
segments(x0=4,x1=-10, y0=16, y1 =16 , col = "red")
```

## Poisson assumptions

- An event can occur $0 \ldots\infty$ times
- Events are independent
- Events cannot occur simultaneously
- Variance equals the mean
- The rate of events is constant

# Rates

## The rate of events

Counts are usually collected over time or space:

- The amount of fish we catch in an hour
- The number of deaths on a population of 10.000
- The number of seizures a patient has during the night
- The number of times a behavior is expressed during a treatment
- Number of pidgeons in a city the size of Los Angeles
- The number of bigfoot reports collected in a small forest, yesterday, by 3 people
- Number of wrongful convictions in Germany last year
- Number of starts in the night sky

## The Poisson distribution: rates

Alternatively we can write:

\begin{equation}
\mathcal{L}(y_i;\Theta) = \text{exp}\{y_i\log(rt) - rt - \log(y_i!)\}
\end{equation}

so, $\lambda = rt$

- $r$ is the rate at which counts occur, per time period $t$
- we can instead write $\lambda = t\exp(\eta)  = \exp\{\eta + \log(t)\}$
- $\log(t)$ is called an \textbf{offset}

## Example: going out fishing

- On average we catch 1 fish in 20 minutes $\lambda = 1 = \exp\{-2.99+\log(20)\}$
- If we go fishing for an hour we catch $\exp(-2.99)*60 = 3$ fish
- If we go fishing for one minute we catch $\exp(-2.99) = \frac{1}{20}$ fish
- Here, $r = \exp(-2.99)$ and $t$ is the time we want to spend fishing
- We can also find the amount of time we need to spend to catch 5 fish
  - $\exp\{-2.99+\log(t)\} = 5$, so $t = \frac{5}{\exp(-2.99)} = 100$ minutes

# Log-linear regression

Log-linear regression is a class of models that uses the log-link function:

\begin{equation}
\begin{aligned}
 \log\{\mathams{E}(y_i\vert x_i)\} &= \eta_i = \alpha + x_i\beta\\
 \mathams{E}(y_i\vert x_i) &= \lambda_i = \exp(\alpha + x_i\beta)
 \end{aligned}
\end{equation}

\textbf{Log-linear regression is commonly used to analyse count data}

## Log-linear regression

Log-linear regression is a "multiplicative" model

\begin{equation}
\begin{aligned}
\lambda_i &= \exp(\alpha + x_i\beta) \\ 
& = \exp(\alpha)\exp(x_i\beta)
\end{aligned}
\end{equation}

\pause

\textbf{A unit increase in $x_i$ scales $\lambda_i$ by $\exp(\beta)$}

So, when $\exp(\beta) = \frac{1}{2}$, $\exp(\alpha)$ halves for every unit of $x_i$\newline
So, when $\exp(\beta) = 2$, $\exp(\alpha)$ doubles for every unit of $x_i$

\pause

\textbf{Of course, this is more involved with multiple predictors}

## Example of a multiplicative process

Say that we have the model:

\begin{equation}
\log(\lambda) = \alpha+x_i\beta
\end{equation}

- with $\alpha = -2.99$ and $\beta = \log(2) \approx 0.693$
- $x_i$ is either 0 or 1: either I was fishing or you were
- $\exp(-2.99) = 0.05$ the average number of fish I caught in the time I spent fishing
- $\exp(-2.99+\log{2}) = \exp(-2.99)*2 = 0.1$ the average number of fish you caught
- So, you caught twice as many fish! I am not very good at fishing


# Example 1

## Example: campus crime

Count of violent crimes for an academic year

\columnsbegin
\column{0.5\textwidth}

![freepik.com](criminal.jpeg)

\column{0.5\textwidth}

![campussecuritytoday.com](campuscrime.jpg)


\columnsend

## Campus crime: the data

Data via Legler and Roback (2021)

- 81 observations
- Number of violent crimes, Total number of crimes, Number of property crimes
- Student enrollment
- Type (University or College)
- Region of the country

\tiny

```{r, echo  =FALSE, message=FALSE, warning=FALSE}
campus <- read.csv("../data/Campus.csv")[,c("num_viol","total_crime","num_prop","Enrollment","type","region")]
campus$region <- as.factor(campus$region)
campus$type <- as.factor(campus$type)
library(tidyr)## Campus crime: the data

knitr::kable(head(campus, 7), format="latex", booktabs = T)%>%kableExtra::kable_styling(position="center")
```

\normalsize

## How could these data be analysed with a binomial regression?

\tiny

```{r, echo  =FALSE, message=FALSE, warning=FALSE}
campus <- read.csv("../data/Campus.csv")[,c("num_viol","total_crime","num_prop","Enrollment","type","region")]
campus$region <- as.factor(campus$region)
campus$type <- as.factor(campus$type)
library(tidyr)
knitr::kable(head(campus, 7), format="latex", booktabs = T)%>%kableExtra::kable_styling(position="center")
```

\normalsize

## What is the relationship between violent crimes and school variables?

```{r, echo  =FALSE, message=FALSE, warning=FALSE, fig.width=13, fig.height=8}
par(mfrow=c(2,2))
plot(jitter(log1p(num_viol)) ~type, data = campus, ylab = "log(Number of violent crimes+1)", cex.lab=1.5, cex.axis = 2.5, cex = 2, xlab="Type")
plot(jitter(log1p(num_viol)) ~Enrollment, data = campus, ylab = NA, yaxt="n", cex.lab=2.5, cex.axis=2.5, cex = 2)
plot(jitter(log1p(num_viol)) ~log1p(total_crime), data = campus, ylab = NA, yaxt="n", cex.lab=2.5, cex.axis=2.5, cex = 2, xlab = "log(Total crime count + 1)")
plot(jitter(log1p(num_viol)) ~region, data = campus, ylab = NA, yaxt="n", cex.lab=2.5, cex.axis=2.5, cex = 2, xlab = "Region")
```

## Campus crime: fit the model

```{r}
model <- glm(num_viol ~ region+type, 
             family = "poisson", data = campus)
```

What issue can we identify for this model?

## What is the relationship between violent crimes per 1000 enrolled and school variables?

```{r, echo  =FALSE, message=FALSE, warning=FALSE, fig.width=13, fig.height=8}
par(mfrow=c(2,2))
plot(jitter(log1p(1000*num_viol/Enrollment)) ~type, data = campus, ylab = "log(1000*Number of violent crimes/Enrollment+1)", cex.lab=1.5, cex.axis = 2.5, cex = 2, xlab="Type")
plot(jitter(log1p(1000*num_viol/Enrollment)) ~Enrollment, data = campus, ylab = NA, yaxt="n", cex.lab=2.5, cex.axis=2.5, cex = 2)
plot(jitter(log1p(1000*num_viol/Enrollment)) ~log1p(total_crime), data = campus, ylab = NA, yaxt="n", cex.lab=2.5, cex.axis=2.5, cex = 2, xlab = "log(Total crime count + 1)")
plot(jitter(log1p(1000*num_viol/Enrollment)) ~region, data = campus, ylab = NA, yaxt="n", cex.lab=2.5, cex.axis=2.5, cex = 2, xlab = "Region")
```

## Campus crime: fit the model

```{r}
modelo <- glm(num_viol ~ region + type 
              + offset(log(Enrollment)), 
             family = "poisson", data = campus)
```

```{r, echo = FALSE}
format(cbind(data.frame("No offset" = coef(model), 
                        "Offset" = coef(modelo))), digits = 2L)
```

## Campus crime: per 1000 enrolled

```{r}
model1000 <- glm(num_viol ~ region + type 
              + offset(log(Enrollment/1000)), 
             family = "poisson", data = campus)
```

$\exp(\alpha_2)*1000 = \exp(\alpha_3)$
$\exp(\alpha_2) = \exp(\alpha_3)/1000$
$\exp(\alpha_2) = \exp\{\alpha_3- \log(1000)\}$

## Campus crime: per 1000 enrolled {.t}

```{r, echo = FALSE}
format(cbind(data.frame("No offset" = coef(model), 
                        "Offset" = coef(modelo)),
                        "Per thousand" = coef(model1000)), digits = 2L)
```

# Overdispersion

## Do we have a good model?

\textbf{More on this after the break}

- Overdispersion or underdispersion
- Zero-inflation

## Overdispersion

Our assumption: $\lambda = \text{var}(\textbf{y})$ \newline
Reality: $\lambda \geq \text{var}(\textbf{y})$

- Mean = variance
- If there is more variation, this assumption fails
- Consequences: CIs underestimate, biased parameter estimates, inflation in model selection

For our example: many females have few satellites, but some females have very many.

## Underdispersion

Our assumption: $\lambda = \text{var}(\textbf{y})$ \newline
Reality: $\lambda \leq \text{var}(\textbf{y})$

Considerably less common than overdispersion.

## Detecting overdispersion

- Residual diagnostics
- $D(\textbf{y};\hat{\symbf{\mu}})/(n-k)$: should be close to 1
- `performance::check_overdispersion` (relies on asymptotics)
- Simulation (later today)

## Dealing with dispersion: options

- Correct for it (calculate dispersion)
- Fit a different model
  - Negative binomial (overdispersion, \texttt{MASS package})
  - Conway-Maxwell Poisson (over- and underdispersion. )
  - Generalized Poisson(over- and underdispersion)
  - Quasi-likelihood models
  - Mixed models (not covered here)

## Quasi-likelihood models

Introduced by [Wedderburn (1974)](https://academic.oup.com/biomet/article-abstract/61/3/439/249095)

- No "real" likelihood is specified for the data
- Means no AIC, but deviance exists
- Largely defined by its variance function

\textbf{For Poisson responses: does not correct the parameter estimates}

## Negative-binomial

\begin{equation}
\mathcal{L}(y_i;\Theta) = \frac{\Gamma(y_i+\phi)}{\Gamma(\phi)y_i!}\biggl(\frac{\phi}{\mu_i+\phi}\biggr)^\phi \biggl(\frac{\mu_i}{\mu_i+\phi}\biggr)^{y_i}
\end{equation}

- $\text{var}(\textbf{y}) = \symbf{\mu} + \frac{\symbf{\mu}^2}{\phi}$
- For large $\phi$ Poisson!
- Requires more data/information due to extra parameter

## Is negative-binomial regression in the EF?

\begin{equation}
\begin{aligned}
\mathcal{L}(y_i;\Theta) = \exp[ \frac{y_i\textcolor{blue}{\log\{\frac{\mu_i}{\mu_i+\phi_i}\}} -\textcolor{red}{\phi\log\{\frac{\mu_i+\phi}{\phi}\}}}{1} + \\ \textcolor{orange}{\log\{\Gamma(y_i+\phi)\} - \log\{\Gamma(\phi)\} - \log(y_i!)}]
\end{aligned}
\end{equation}

All GLMs can be formulated as:

\begin{equation}
\mathcal{L}(y_i;\Theta) = \text{exp}\{\frac{y_i\textcolor{blue}{\eta_i}-\textcolor{red}{b(\eta_i)}}{\textcolor{pink}{a(\phi)}} +\textcolor{orange}{c(y_i,\phi)}\}
\end{equation}

<!-- ## Negative-binomial: alternative parameterization -->

<!-- The negative-binomial is usually parameterized in terms of: -->

<!-- \begin{itemize} -->
<!-- \itemsep-0.5em -->
<!-- \item The number of "successes" $r = \phi$ -->
<!-- \item The number of "failures" $n-r = y_i$ -->
<!-- \item The probability of "success" $p_i = \frac{\phi}{\mu+\phi}$ -->
<!-- \item The probability of "failure" $1-p_i = \frac{\mu_i}{\mu_i+\phi}$ -->
<!-- \end{itemize} -->

# Example 2

## Example: hurricanes 

Deaths due to hurricanes

![climaterealityproject.org](hurricane.jpg){height=70%}

## Hurricanes: the data

Data from Jung et al. (2914)

- 94 observations
- Year, name, Binary name categorization (male, female), Masulinity-Femininity score, strength of the hurricane, prior air pressure
- Excluded two outliers

\tiny

```{r, echo  =FALSE, message=FALSE, warning=FALSE}
data(hurricanes, package="DHARMa")
hurricanes <- hurricanes[-c(10,34),]
hurricanes$Gender_MF  <- factor(hurricanes$Gender_MF,levels = c(0,1), labels=c("Male", "Female"))
hurricanes$Category <- as.factor(hurricanes$Category)
library(tidyr)
knitr::kable(head(hurricanes[,-5], 7), format="latex", booktabs = T)%>%kableExtra::kable_styling(position="center")
```

\normalsize

## Are female hurricanes more deadline than male hurricanes?

\vspace*{-\baselineskip}

```{r, echo  =FALSE, message=FALSE, warning=FALSE, fig.width=13, fig.height=8}
par(mfrow=c(2,2))
plot(jitter(log1p(alldeaths)) ~Gender_MF, data = hurricanes, ylab = "log(Total deaths+1)", cex.lab=1.5, cex.axis = 2.5, cex = 2)
plot(jitter(log1p(alldeaths)) ~Category, data = hurricanes, ylab = NA, yaxt="n", cex.lab=2.5, cex.axis=2.5, cex = 2)
plot(jitter(log1p(alldeaths)) ~MinPressure_before, data = hurricanes, ylab = NA, yaxt="n", cex.lab=2.5, cex.axis=2.5, cex = 2)
plot(jitter(log1p(alldeaths)) ~NDAM, data = hurricanes, ylab = NA, yaxt="n", cex.lab=2.5, cex.axis=2.5, cex = 2)
```

## Hurricanes: fit the model

```{r}
modelp <- glm(alldeaths ~ Gender_MF + MinPressure_before, 
             family = "poisson", data = hurricanes)
```

## Hurricanes: interpreting parameters

\small
```{r echo = FALSE}
signif(summary(modelp)$coefficients, digits = 2L)
```
\normalsize

How do we interpret the intercept?

## Hurricanes: interpreting parameters

\small
```{r echo = FALSE}
hurricanes$MinPressure_beforeC <- hurricanes$MinPressure_before-mean(hurricanes$MinPressure_before)
modelp1 <- glm(alldeaths ~ Gender_MF + MinPressure_beforeC, 
             family = "poisson", data = hurricanes)
signif(summary(modelp1)$coefficients,digits = 2L)
```

<!-- (Intercept) = Light-medium coloured females with both spines in good condition\newline -->

__Average prior air pressure: `r round(mean(hurricanes$MinPressure_before),2)` knots __ \newline

How do we interpret the intercept? \newline
And its standard error?

\textcolor{red}{Prior air pressure centered}
 
## Hurricanes: interpreting parameters on the __response scale__

\footnotesize
- (Intercept) = Male-named hurricanes, prior air pressure $\approx$ 965
- Female-named hurricanes: $\exp(0.27) = 1.3$, so 30% more deadly

## Hurricanes: visual interpretation

\small
```{r, echo  =FALSE, message=FALSE, warning=FALSE, fig.width=13, fig.height=8}
plot(effects::allEffects(modelp1))
```

## Hurricanes: checking overdispersion

```{r}
performance::check_overdispersion(modelp1)
```

## Hurricanes: Negative-binomial

\small
```{r}
modelnb <- MASS::glm.nb(alldeaths ~ Gender_MF + MinPressure_beforeC, data = hurricanes)
```

\normalsize

and compare the models:

```{r}
AIC(modelp1, modelnb)
```

## Hurricanes crabs: comparing estimates

\footnotesize

```{r, echo = FALSE}
cbind("Poisson estimate"=signif(coef(modelp1), 2L), "NB estimate" = signif(coef(modelnb), 2L), "Poisson SE" = signif(summary(modelp1)$coef[,2],2L), "NB SE"= signif(summary(modelnb)$coef[,2],2L))
```

\normalsize

- SEs have increased
- Coefficients have changed
- \textbf{Female and male-named hurricanes are equally deadly}
- Effect of pressure has remained

## Count distributions

- Poisson
- Negative binomial (two types, with dispersion)
- Conway-Maxwell Poisson (with dispersion)
- Generalized Poisson (with dispersion)
- Skellam distribution (difference of counts)
- Binomial distribution (counts with a maximum)
- Truncated distributions (e.g., without zeros)
- Quasi-likelihood models

# Summary

- Counts are analysed with log-linear models
- The collection effort of counts needs to be considered (offset)
- When the Poisson assumption is violated, we change to another count distribution
